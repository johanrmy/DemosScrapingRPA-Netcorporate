## Proyectos de Web Scraping con Scrapy, Selenium y Automatizaci칩n RPA 
### Repositorio que re칰ne ejemplos pr치cticos y demos de dos tecnolog칤as: Scrapy y Selenium.
#### 游댌 Web Scraping con Scrapy: El framework Scrapy es implementado al extraer datos de renting de un producto en una p치gina de acceso abierto en el dominio de Netcorporate
#### 游깷 Web Scraping con Selenium: Las herramientas de Selenium facilitan aun m치s la extraci칩n de datos en p치ginas web sacrificando el tiempo de ejecuci칩n a grandes cantidades de datos.
#### 游뱄 Automatizaci칩n RPA con Selenium: Desarrollar tareas repetitivas para la extracci칩n de datos en p치ginas protegidas con el dominio PyWombat.
## Crear entorno virtual e instalar librer칤as
#### Para entornos Conda :
```
conda create --name <env> --file requirements.txt
``` 
## Ejecuci칩n de programa
#### Este repositorio cuenta con dos scripts, en `spider_web/spiders`
### `netcorporate.py`
#### Extrae datos de un producto de renting en el dominio Netcorporate usando el framework Scrapy
###### El resultado se muestra en la consola :

```
scrapy crawl netcorporate
``` 
###### Resultado importado en archivo csv :

```
scrapy crawl netcorporate -o producto.csv
```
###### Resultado importado en archivo json :
```
scrapy crawl netcorporate -o producto.json
```
---
### `rpa_scrapy_test.py`
#### Extrae datos de una lista de ejercicios realizados en una p치gina protegida del dominio PyWombat usando Selenium.
##### Antes de ejecutar el script debe ingresar credenciales v치lidas de `USERNAME` y `PASSWORD` en el archivo `spider_web/vars.py` para iniciar sesi칩n.
###### El resultado se muestra en la consola :

```
scrapy crawl rpa_scrapy_test
``` 
###### Resultado importado en archivo csv :

```
scrapy crawl rpa_scrapy_test -o data.csv
```
###### Resultado importado en archivo json :
```
scrapy crawl rpa_scrapy_test -o data.json
```
#### Los comandos deben ejecutarse en la ruta root, a nivel del archivo `scrapy.cfg`.
